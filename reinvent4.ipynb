{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "REINVENT4 = \"~/Documents/apps/REINVENT4/\" # set your REINVENT4 path here, originally should be clone from https://github.com/REINVENT-AI/REINVENT4\n",
    "toml = \"~/Documents/apps/REINVENT4/configs/toml/\"\n",
    "prior = \"~/Documents/apps/REINVENT4/priors/\"\n",
    "wd = \"/tmp/R4_notebooks_output/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete existing working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(wd, ignore_errors=True)\n",
    "os.mkdir(wd)\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_parameters = '''\n",
    "run_type = \"sampling\"\n",
    "device = \"mps\"\n",
    "json_out_config = \"_sampling.json\"\n",
    "\n",
    "model_file = \"~/Documents/apps/REINVENT4/priors/reinvent.prior\"\n",
    "output_file = \"/tmp/R4_notebooks_output/sampling_out.csv\"\n",
    "num_smiles = 150\n",
    "unique_molecules = True\n",
    "randomize_smiles = True\n",
    "'''\n",
    "sampling_toml = '/tmp/R4_notebooks_output/sampling.toml'\n",
    "\n",
    "with open(sampling_toml, 'w') as f:\n",
    "    f.write(global_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_parameters = '''\n",
    "# REINVENT4 TOML input example for sampling\n",
    "#\n",
    "\n",
    "\n",
    "run_type = \"sampling\"\n",
    "device = \"mps\"  # set torch device e.g. \"cpu\". For macOS, use \"mps\"\n",
    "json_out_config = \"_sampling.json\"  # write this TOML to JSON\n",
    "\n",
    "\n",
    "[parameters]\n",
    "\n",
    "# Uncomment one of the comment blocks below.  Each generator needs a model\n",
    "# file and possibly a SMILES file with seed structures.\n",
    "\n",
    "## Reinvent: de novo sampling\n",
    "model_file = \"priors/reinvent.prior\"\n",
    "\n",
    "## LibInvent: find R-groups for the given scaffolds\n",
    "#model_file = \"priors/libinvent.prior\"\n",
    "#smiles_file = \"configs/toml/scaffolds.smi\"  # 1 scaffold per line with attachment points\n",
    "\n",
    "## LinkInvent: find a linker/scaffold to link two fragments\n",
    "#model_file = \"priors/linkinvent.prior\"\n",
    "#smiles_file = \"configs/toml/warheads.smi\"  # 2 warheads per line separated with '|'\n",
    "\n",
    "## Mol2Mol: find molecules similar to the provided molecules\n",
    "#model_file = \"priors/mol2mol_medium_similarity.prior\"\n",
    "#smiles_file = \"mol2mol.smi\"  # 1 compound per line\n",
    "#sample_strategy = \"beamsearch\"  # multinomial or beamsearch (deterministic)\n",
    "#temperature = 1.0 # temperature in multinomial sampling\n",
    "#tb_logdir = \"tb_logs\"  # name of the TensorBoard logging directory\n",
    "\n",
    "output_file = '/tmp/R4_notebooks_output/sampling.csv'  # sampled SMILES and NLL in CSV format\n",
    "\n",
    "num_smiles = 157  # number of SMILES to be sampled, 1 per input SMILES\n",
    "unique_molecules = true  # if true remove all duplicatesd canonicalize smiles\n",
    "randomize_smiles = true # if true shuffle atoms in SMILES randomly\n",
    "'''\n",
    "sampling_toml = '/tmp/R4_notebooks_output/sampling.toml'\n",
    "\n",
    "with open(sampling_toml, 'w') as f:\n",
    "    f.write(global_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is accessible\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/keetane/Documents/apps/REINVENT4/priors/reinvent.prior\", \"r\") as file:\n",
    "    print(\"File is accessible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/bin/reinvent\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/Reinvent.py\", line 334, in main\n",
      "    runner(\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/runmodes/samplers/run_sampling.py\", line 55, in run_sampling\n",
      "    adapter, _, model_type = create_adapter(agent_model_filename, \"inference\", device)\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/runmodes/create_adapter.py\", line 30, in create_adapter\n",
      "    dict_filename = resolve_model_filename(dict_filename)\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/runmodes/create_adapter.py\", line 81, in resolve_model_filename\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: model file /Users/keetane/Documents/cheats/priors/reinvent.prior is not accessible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call(\n",
    "['/Users/keetane/opt/anaconda3/envs/r4/bin/reinvent', '-l', 'sampling.log', '/tmp/R4_notebooks_output/sampling.toml']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:13:33 <INFO> Started REINVENT 4.4.22 (C) AstraZeneca 2017, 2023 on 2025-03-17\n",
      "23:13:33 <INFO> Command line: /Users/keetane/opt/anaconda3/envs/r4/bin/reinvent /tmp/R4_notebooks_output/sampling.toml\n",
      "23:13:33 <INFO> User keetane on host KeetaneMacMini.local\n",
      "23:13:33 <INFO> Python version 3.10.16\n",
      "23:13:33 <INFO> PyTorch version 2.2.1, git 6c8c5ad5eaf47a62fafbb4a2747198cbffbf1ff0\n",
      "23:13:33 <INFO> PyTorch compiled with CUDA version None\n",
      "23:13:33 <INFO> RDKit version 2022.09.5\n",
      "23:13:33 <INFO> Platform macOS-15.1-arm64-arm-64bit\n",
      "23:13:33 <INFO> Number of PyTorch CUDA devices 0\n",
      "23:13:33 <INFO> Using CPU arm\n",
      "23:13:33 <INFO> Writing JSON config file to /Users/keetane/Documents/cheats/_sampling.json\n",
      "23:13:33 <INFO> Starting Sampling\n",
      "23:13:33 <CRIT> model file /Users/keetane/Documents/cheats/priors/reinvent.prior is not accessible\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/bin/reinvent\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/Reinvent.py\", line 334, in main\n",
      "    runner(\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/runmodes/samplers/run_sampling.py\", line 55, in run_sampling\n",
      "    adapter, _, model_type = create_adapter(agent_model_filename, \"inference\", device)\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/runmodes/create_adapter.py\", line 30, in create_adapter\n",
      "    dict_filename = resolve_model_filename(dict_filename)\n",
      "  File \"/Users/keetane/opt/anaconda3/envs/r4/lib/python3.10/site-packages/reinvent/runmodes/create_adapter.py\", line 81, in resolve_model_filename\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: model file /Users/keetane/Documents/cheats/priors/reinvent.prior is not accessible\n",
      "CPU times: user 18.6 ms, sys: 10.6 ms, total: 29.2 ms\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!reinvent /tmp/R4_notebooks_output/sampling.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run_type = \"sampling\"\n",
      "device = \"mps\"  # set torch device e.g. \"cpu\". For macOS, use \"mps\"\n",
      "json_out_config = \"_sampling.json\"  # write this TOML to JSON\n",
      "\n",
      "model_file = \"~/Documents/apps/REINVENT4/priors/reinvent.prior\"\n",
      "output_file = \"/tmp/R4_notebooks_output/sampling_out.csv\"\n",
      "num_smiles = 150\n",
      "unique_molecules = True\n",
      "randomize_smiles = True\n"
     ]
    }
   ],
   "source": [
    "cat $sampling_toml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
